# 0.1.2 Minor Updates

In this release we have:

  - Added support for the lazy Adam optimizer and the
    [YellowFin](https://arxiv.org/pdf/1706.03471.pdf) optimizer.
  - Added more learning rate decay schemes:
    - Cosine decay.
    - Cycle-linear 10x decay.
    - Square-root decay.
    - More warm-up decay schedules.
  - Fixed some bugs related to variable scopes and variable sharing.
  - Added support for some new image-related ops, under the namespace
    `tf.image`.
  - Improved consistency for the creation of initializer ops.
  - Added support for the `tf.initializer` op creation context.
  - Exposed part of the `TensorArray` API.
  - Exposed `tf.Op.Builder` in the public API.
  - Improvements to the learn API:
    - Improved the evaluator hook.
    - Removed the layer creation context mechanism, to be refactored
      later. It was causing some issues due to bad design and unclear
      semantics. The plan is to implement this, in the near future, as
      wrapper creation context layers.
    - Improved the `Model` class.
    - Fixed a bug that was causing some issues related to inference
      hooks in the in-memory estimator.
    - Improved logging.
